# -tica-IA
# Relatório – Dilema Ético em IA: Reconhecimento Facial

👉 Um algoritmo pode reforçar desigualdades?  
Analisamos o dilema ético do **reconhecimento facial**.

---

## 📌 O Problema
Sistemas de reconhecimento facial, usados por polícias e empresas, apresentam **erros desproporcionais** ao identificar pessoas negras e mulheres.  
Estudos do MIT apontaram que a taxa de falhas pode ser até **100 vezes maior** em comparação com rostos brancos.  
Além disso, há riscos graves de **violação da privacidade** e de uso abusivo para vigilância em massa.

---

## 🔎 Nossa Análise
- O sistema é uma **“caixa preta”**, sem transparência sobre como decisões são tomadas.  
- Há um **viés algorítmico e de dados**: bancos de imagens pouco diversos treinam modelos que reproduzem desigualdades.  
- Impactos sociais incluem **prisões injustas, reforço do racismo estrutural** e ameaça a direitos fundamentais garantidos pela **LGPD**.  

---

## 🧭 Nosso Posicionamento
O uso irrestrito de reconhecimento facial na segurança pública deve ser **limitado ou banido**.  

Recomendamos que:  
1. Adoção de **auditorias independentes** para avaliar viés antes do uso.  
2. Criação de **leis específicas** para regulamentar seu emprego em segurança.  
3. Uso restrito a contextos com **supervisão humana e transparência**.  

💡 A tecnologia pode ser inovadora, mas não à custa da justiça social.  
Como profissionais, precisamos garantir que a IA respeite direitos fundamentais.

---

## 📂 Relatório Completo
👉 [Clique aqui para acessar o PDF da análise]

---

### 🔖 Hashtags
#ÉticaEmIA #ReconhecimentoFacial #ViésAlgorítmico #LGPD #JustiçaTecnológica
